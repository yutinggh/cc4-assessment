{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the following fields and store the data as restaurants.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "   ---------------------------------------- 0.0/250.0 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 30.7/250.0 kB 640.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  245.8/250.0 kB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 250.0/250.0 kB 2.2 MB/s eta 0:00:00\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests, openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been extracted and stored in restaurants.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the JSON data\n",
    "url = \"https://raw.githubusercontent.com/Papagoat/brain-assessment/main/restaurant_data.json\"\n",
    "\n",
    "# Fetch the JSON data from the URL\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Load country codes using pandas\n",
    "country_mapping = {}\n",
    "country_code_file = 'Country-Code.xlsx'\n",
    "country_code_df = pd.read_excel(country_code_file)\n",
    "for index, row in country_code_df.iterrows():\n",
    "    country_mapping[row['Country Code']] = row['Country']\n",
    "\n",
    "# Extract fields and write to CSV\n",
    "with open('restaurants.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # Write header\n",
    "    writer.writerow(['Restaurant Id', 'Restaurant Name', 'Country', 'City', 'User Rating Votes', 'User Aggregate Rating', 'Cuisines'])\n",
    "\n",
    "    # Extract information for each restaurant\n",
    "    for result in data:\n",
    "        restaurants = result.get('restaurants', [])\n",
    "        for restaurant_info in restaurants:\n",
    "            restaurant = restaurant_info.get('restaurant', {})\n",
    "            restaurant_id = restaurant.get('R', {}).get('res_id', '')\n",
    "            restaurant_name = restaurant.get('name', '')\n",
    "            country_code = restaurant.get('location', {}).get('country_id', '')\n",
    "            country = country_mapping.get(country_code, '')\n",
    "            city = restaurant.get('location', {}).get('city', '')\n",
    "            user_rating_votes = restaurant.get('user_rating', {}).get('votes', '')\n",
    "            user_aggregate_rating = restaurant.get('user_rating', {}).get('aggregate_rating', '')\n",
    "            cuisines = restaurant.get('cuisines', '')\n",
    "\n",
    "            # Write data to CSV\n",
    "            writer.writerow([restaurant_id, restaurant_name, country, city, user_rating_votes, user_aggregate_rating, cuisines])\n",
    "\n",
    "print(\"Data has been extracted and stored in restaurants.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the list of restaurants that have past event in the month of April 2019 and store the data as restaurant_events.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been extracted and stored in restaurant_events.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to check if the event falls within April 2019\n",
    "def is_april_2019(event_date):\n",
    "    try:\n",
    "        date_obj = datetime.strptime(event_date, '%Y-%m-%d')\n",
    "        return date_obj.year == 2019 and date_obj.month == 4\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Function to replace empty values with \"NA\"\n",
    "def replace_empty(value):\n",
    "    return value if value else \"NA\"\n",
    "\n",
    "# URL of the JSON data\n",
    "url = \"https://raw.githubusercontent.com/Papagoat/brain-assessment/main/restaurant_data.json\"\n",
    "\n",
    "# Fetch the JSON data from the URL\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Extract fields and write to CSV\n",
    "with open('restaurant_events.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # Write header\n",
    "    writer.writerow(['Event Id', 'Restaurant Id', 'Restaurant Name', 'Photo URL', 'Event Title', 'Event Start Date', 'Event End Date'])\n",
    "\n",
    "    # Extract information for each restaurant with past events in April 2019\n",
    "    for result in data:\n",
    "        restaurants = result.get('restaurants', [])\n",
    "        for restaurant_info in restaurants:\n",
    "            restaurant = restaurant_info.get('restaurant', {})\n",
    "            events = restaurant.get('zomato_events', [])\n",
    "            for event_info in events:\n",
    "                event = event_info.get('event', {})\n",
    "                event_start_date = event.get('start_date', '')\n",
    "                event_end_date = event.get('end_date', '')\n",
    "                if is_april_2019(event_start_date):\n",
    "                    event_id = event.get('event_id', '')\n",
    "                    restaurant_id = restaurant.get('R', {}).get('res_id', '')\n",
    "                    restaurant_name = restaurant.get('name', '')\n",
    "                    event_title = event.get('title', '')\n",
    "                    photo_url = replace_empty(event['photos'][0]['photo'].get('url', '') if event.get('photos') else '')\n",
    "\n",
    "                    # Write data to CSV\n",
    "                    writer.writerow([event_id, restaurant_id, restaurant_name, photo_url, event_title, event_start_date, event_end_date])\n",
    "\n",
    "print(\"Data has been extracted and stored in restaurant_events.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the dataset (restaurant_data.json), determine the threshold for the different rating text based on aggregate rating. Return aggregates for the following ratings only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excellent: Min - 4.5, Max - 4.9\n",
      "Very Good: Min - 4.0, Max - 4.4\n",
      "Good: Min - 3.5, Max - 3.9\n",
      "Average: Min - 2.5, Max - 3.4\n",
      "Poor: Min - 2.2, Max - 2.2\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL of the JSON data\n",
    "url = \"https://raw.githubusercontent.com/Papagoat/brain-assessment/main/restaurant_data.json\"\n",
    "\n",
    "# Fetch the JSON data from the URL\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Initialize dictionaries to store aggregate ratings for different rating texts\n",
    "rating_thresholds = {\n",
    "    \"Excellent\": {\"min\": float('inf'), \"max\": float('-inf')},\n",
    "    \"Very Good\": {\"min\": float('inf'), \"max\": float('-inf')},\n",
    "    \"Good\": {\"min\": float('inf'), \"max\": float('-inf')},\n",
    "    \"Average\": {\"min\": float('inf'), \"max\": float('-inf')},\n",
    "    \"Poor\": {\"min\": float('inf'), \"max\": float('-inf')}\n",
    "}\n",
    "\n",
    "# Iterate through the data to find rating thresholds\n",
    "for result in data:\n",
    "    restaurants = result.get('restaurants', [])\n",
    "    for restaurant_info in restaurants:\n",
    "        restaurant = restaurant_info.get('restaurant', {})\n",
    "        user_rating = restaurant.get('user_rating', {})\n",
    "        aggregate_rating = float(user_rating.get('aggregate_rating', 0))\n",
    "        rating_text = user_rating.get('rating_text', '')\n",
    "\n",
    "        # Update rating thresholds\n",
    "        if rating_text in rating_thresholds:\n",
    "            if aggregate_rating < rating_thresholds[rating_text][\"min\"]:\n",
    "                rating_thresholds[rating_text][\"min\"] = aggregate_rating\n",
    "            if aggregate_rating > rating_thresholds[rating_text][\"max\"]:\n",
    "                rating_thresholds[rating_text][\"max\"] = aggregate_rating\n",
    "\n",
    "# Print the rating thresholds\n",
    "for rating_text, thresholds in rating_thresholds.items():\n",
    "    print(f\"{rating_text}: Min - {thresholds['min']}, Max - {thresholds['max']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
